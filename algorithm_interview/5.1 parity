## 5.1 Computing the parity of a word( 奇偶校验)

1. Brute-force algorithm

   1. It iteratively tests the value of each bit while tracking the number of 1s seen so far.

      ```JAVA
      public static short parity(long x){
          short res = 0;
          while(x != 0){
              result ^= (x & 1);
              // ^ means XOR: 1 XOR 0 or 0 XOR 1 result in 1, otherwise result is 0;
              // eg. A ^ A = 0;
              x >>>= 1;
          }
          return res;
      }
      ```

      The time complexity is O(n), which n is the word size.

   

   2. Refinement
      If we know x & (x-1) could erase the lowest set bit in a word in a single operation, this can be used to improve performance in the best- and average-cases.

      ```java
      public static short parity(long x){
          short res = 0;
          while(x != 0){
              res ^= 1;
              x = x & (x-1);
          }
          return res;
      }
      ```

      The time complexity is O(k), which k is the number of bits set to 1 in a particular word.

      

2. Caching.
   Illustrate the approach with a lookup table for 2-bit words.
   eg. (11 00 10 10)<sub>2</sub>  The cache is <0, 0, 1, 1> -- these are parities of (11), (00), (10), (10) respectively.

   ```java
   public static short parity(long x){
       final int WORD_SIZE = 16;
       final int BIT_MADK = 0xFFFF;
       return (short) (
       	precomputedParity[(int)((x >>> (3 * WORD_SIZE)) & BIT_MASK)]
       	^ precomputedParity[(int)((x >>> (2 * WORD_SIZE)) & BIT_MASK)]
       	^ precomputedParity[(int)((x >>> WORD_SIZE)) & BIT_MASK]
       	^ precomputedParity[(int)(x & BIT_MASK)]);
   }
   ```

   The time complexity is a function of the size of the keys used to index the lookup table. Let L be the width of the words for which we cache the results, and n the word size. Since there are n/L terms, the time complexity is O(n/L), assuming word level operations, such as shifting, take O(1) time.

3. Word level operation
   XOR has the property of being associative(结合律), as well as commutative(交换律), i.e., the order in which we perform the XORs does not influence the result.
   We illustrate the approach with an 8-bit word. The parity of (11010111)<sub>2</sub> is the same as the parity of (1101) <sub>2</sub>XORed with (0111)<sub>2</sub>.

   ```java
   public static short parity(long x){
       x ^= x >>> 32;
       x ^= x >>> 16;
       x ^= x >>> 8;
       // 1101 0111
       x ^= x >>> 4;
       // **** 1010
       x ^= x >>> 2;
       // **** **00
       x ^= x >>> 1;
       // **** ***1
       return (short)(x & 0x1);
   }
   ```

   The time complexity is O(log n), where n is the word size.

   *Note that we could have combined caching with word-level operations, e.g., by doing a lookup once we get to 16 bits. The actual runtimes depend on the input data, e.g., the refinement of the brute-force algorithm is very fast on sparse inputs. However, for random inputs, the refinement of the brute-force is roughly 20% faster than the brute-force algorithm. The table-based approach is four times faster still, and using associativity reduces run time by another factor of two.* 

   

   ***

   ### Leetcode problem

